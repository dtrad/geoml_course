{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb679c80",
   "metadata": {},
   "source": [
    "# Assignment 2 \n",
    "Due date, November 13, 2022 - Max Grade - 10\n",
    "## Exercise 1: (5/10): Clustering\n",
    "In this exercise you have to pick velocities from a given semblance plot and use them for NMO correction of a CMP.\\\n",
    "Several parts of the assigment are given, just complete the missing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7287b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wiggle.wiggle import wiggle\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e591e6",
   "metadata": {},
   "source": [
    "Panel produced in Seismic Unix from a finite difference shot from the Marmousi model.\\\n",
    "The semblance panel is calculated as follows:\n",
    "> suvelan nv=120 dv=50 fv=1500 < panel_proc.3012 > semb.3012b \\\n",
    "> sustrip < semb.3012b > sembbin.3012b \n",
    "\n",
    "The file \"sembbin.3012b\" is a binary file with dimensions 146 x 120.\n",
    "The horizontal (velocity) and vertical (time) axes are specified below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a623fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv=120  # number of velocities\n",
    "dv=50   # velocity interval \n",
    "fv=1500  # first velocity\n",
    "dts=0.02 # time interval for semblance\n",
    "nts=146  # number of time samples for semblance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d900348f",
   "metadata": {},
   "source": [
    "Read the semblance in numpy, resample to nv, nts, and plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "semb = np.fromfile('sembbin.3012b', dtype='float32')\n",
    "semb=semb.reshape((nv,nts))\n",
    "semb=semb.T\n",
    "plt.imshow(semb);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "[nts,nvs] = semb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a71d7db",
   "metadata": {},
   "source": [
    "We can define the axes (velaxis and timeaxis) as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c754b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velocities for semblance\n",
    "velaxis = np.arange(nvs)*dv+fv\n",
    "timeaxis = np.arange(nts)*dts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf97e2b",
   "metadata": {},
   "source": [
    "We define 2 numpy arrays called tpair and xpair, containing the times and velocities for each high value on the semblance plot. \n",
    "* Scan every element on the semblance plot (loop in nvx and nts) \n",
    "* if the value of the plot is larger than a threshold, store the t,x values on the numpy arrays.\n",
    "* You can define a corridor of minimum/maximum velocities that changes with time to help the picking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[timeaxis.min(),timeaxis.max()]\n",
    "y=[1500,3200]\n",
    "tol=500\n",
    "tpair = []\n",
    "xpair = []\n",
    "vthres= [np.interp(j*dts, x, y) for j in range(nts)]\n",
    "vthres = np.array(vthres)\n",
    "vthresplus = vthres+tol\n",
    "vthresminus= vthres-tol\n",
    "threshold=np.percentile(semb,95)\n",
    "for i in range(nvs):\n",
    "    vel_loc = velaxis[i]    \n",
    "    for j in range(nts):        \n",
    "        if semb[j,i] >= threshold and vel_loc < vthresplus[j] and vel_loc > vthresminus[j]:            \n",
    "            tpair = np.append(tpair, timeaxis[j])\n",
    "            xpair = np.append(xpair, velaxis[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7cf71",
   "metadata": {},
   "source": [
    "Plot the picks (and the corridor if you used one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xpair,tpair)\n",
    "plt.scatter(vthresminus,timeaxis)\n",
    "plt.scatter(vthresplus,timeaxis)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19e4fa8",
   "metadata": {},
   "source": [
    "### Apply clustering techniques to obtain velocities\n",
    "This is the main part of the exercise. We want to pick the t,vel pairs we have from before.\\\n",
    "There are many points, but we want to obtain on per time, so the velocity as a function of time is **monovalued**.\\\n",
    "You can try *kmeans, dbscan, gaussian mixtures,* or any other techniques you like.\\\n",
    "TIP: do not forget to scale the data (and descale after) when needed. Is it always needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7a05f",
   "metadata": {},
   "source": [
    "# Provided plotting functions from the practices.\n",
    "Below there are several plotting functions for Gaussian mixtures, Kmeans and dbscan.\n",
    "Use them if needed to plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73432068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X):\n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "\n",
    "def plot_centroids(centroids, weights=None, circle_color='w', cross_color='k'):\n",
    "    if weights is not None:\n",
    "        centroids = centroids[weights > weights.max() / 10]\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='o', s=30, linewidths=8,\n",
    "                color=circle_color, zorder=10, alpha=0.9)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='x', s=20, linewidths=20,\n",
    "                color=cross_color, zorder=11, alpha=1)\n",
    "\n",
    "def plot_decision_boundaries(clusterer, X, resolution=1000, show_centroids=True,\n",
    "                             show_xlabels=True, show_ylabels=True):\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
    "                         np.linspace(mins[1], maxs[1], resolution))\n",
    "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                cmap=\"Pastel2\")\n",
    "    plt.contour(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                linewidths=1, colors='k')\n",
    "    plot_data(X)\n",
    "    if show_centroids:\n",
    "        plot_centroids(clusterer.cluster_centers_)\n",
    "\n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)\n",
    "    plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d13d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "def plot_gaussian_mixture(clusterer, X, resolution=1000):\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
    "                         np.linspace(mins[1], maxs[1], resolution))\n",
    "    # gmm.score_samples: Compute the weighted log probabilities for each sample.\n",
    "    Z = -clusterer.score_samples(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z,norm=LogNorm(vmin=1.0, vmax=30.0),\n",
    "                 levels=np.logspace(0, 2, 12))\n",
    "    plt.contour(xx, yy, Z, norm=LogNorm(vmin=1.0, vmax=30.0),\n",
    "                levels=np.logspace(0, 2, 12),\n",
    "                linewidths=1, colors='k')\n",
    "\n",
    "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, linewidths=2, colors='r', linestyles='dashed')\n",
    "    \n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "    plot_centroids(clusterer.means_, clusterer.weights_)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6588a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dbscan(dbscan, X, size, show_xlabels=True, show_ylabels=True):\n",
    "    core_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n",
    "    core_mask[dbscan.core_sample_indices_] = True\n",
    "    anomalies_mask = dbscan.labels_ == -1\n",
    "    non_core_mask = ~(core_mask | anomalies_mask)\n",
    "\n",
    "    cores = dbscan.components_\n",
    "    anomalies = X[anomalies_mask]\n",
    "    non_cores = X[non_core_mask]\n",
    "    \n",
    "    #plt.scatter(cores[:, 0], cores[:, 1],c=dbscan.labels_[core_mask], marker='o', s=size, cmap=\"Paired\")\n",
    "    plt.scatter(cores[:, 0], cores[:, 1], marker='*', s=20, c=dbscan.labels_[core_mask])\n",
    "    #plt.scatter(anomalies[:, 0], anomalies[:, 1],c=\"r\", marker=\".\", s=100)\n",
    "    #plt.scatter(non_cores[:, 0], non_cores[:, 1], c=dbscan.labels_[non_core_mask], marker=\".\")\n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"eps={:.2f}, min_samples={}\".format(dbscan.eps, dbscan.min_samples), fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ece89",
   "metadata": {},
   "source": [
    "### Interpolate velocities to a regular time axis with the same dt as the data\n",
    "The velocities we picked above are located at irregular intervals in time (approximately where reflectors occur).\\\n",
    "For using them in a NMO correction program, you need to interpolate them into a regular time axis.\\\n",
    "There are many ways to do this. For example, if you have the centers from kmeans, you could do this:\n",
    "* read the centers from the clustering class\n",
    "* apply inverse scaling if you use scaling\n",
    "* sort them using numpy (interpolation usually requires monotically growing functions)\n",
    "* putting the sorted values in pairs time, velocity\n",
    "* use numpy.interp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5969e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sort before interpolation\n",
    "km = kmeans.cluster_centers_\n",
    "ks = scaler.inverse_transform(km)\n",
    "kss=ks[np.argsort(ks[:,1]),:]\n",
    "kms=km[np.argsort(km[:,1]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e107df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Linear interpolation between points to obtain velocity trend\n",
    "ks_x=kss[:,0]\n",
    "ks_t=kss[:,1]\n",
    "km_x=kms[:,0]\n",
    "km_t=kms[:,1]\n",
    "ks_x.sort()\n",
    "ks_t.sort()\n",
    "km_x.sort()\n",
    "km_t.sort()\n",
    "v_pair = np.reshape(ks_x,(len(ks_x),))\n",
    "t_pair = np.reshape(ks_t,(len(ks_t),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ce824",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt=726\n",
    "dt=0.004\n",
    "cdptime=np.arange(nt)*dt\n",
    "t_vnmo = np.reshape(cdptime,(len(cdptime),))\n",
    "l_vnmo = np.interp(t_vnmo,t_pair,v_pair) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb25f67",
   "metadata": {},
   "source": [
    "### Apply NMO to the gather\n",
    "The CMP gather is given in file cdp.3012b, the offset is in file offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f034e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nt=726\n",
    "nx=48\n",
    "dt=0.004\n",
    "cdp = np.fromfile('cdp.3012b', dtype='float32')\n",
    "cdp=cdp.reshape((nx,nt))\n",
    "cdp=cdp.T\n",
    "cdptime=np.arange(nt)*dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset= np.fromfile('offset.txt',dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "\n",
    "with codecs.open('offset.txt', encoding='utf-8-sig') as f:\n",
    "    offset = np.loadtxt(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fdfb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CDP\n",
    "wiggle(cdp, cdptime, offset,sf= 0.08)\n",
    "plt.xlabel(\"Trace number \", fontsize=13)\n",
    "plt.ylabel(\"Time (s)\", fontsize=13)\n",
    "plt.title(\"Original CDP Gather\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce67acb",
   "metadata": {},
   "source": [
    "Assuming you wrote your interpolated VRMS into cdptime and l_vnmo, you can use flat the gather using the NMO function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c1f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdpc=np.zeros(shape=cdp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee37504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop in time: find pair t0 and vnmo from 1D profile\n",
    "# Loop per offset, calculate the \"corrected time\" based on t0 and Vnmo, \n",
    "# access its correspondent indice in time and copy in the corrected gather these values\n",
    "for i in range(nt):\n",
    "    t0 = cdptime[i]\n",
    "    vlnmo = l_vnmo[i]\n",
    "    for j in range(len(offset)):\n",
    "        tc = np.sqrt(t0**2 + offset[j]**2/vlnmo**2)\n",
    "        #print(tc)\n",
    "        tc_ind = round(tc/dt)\n",
    "        #print(tc_ind)\n",
    "        if tc_ind<nt:\n",
    "            cdpc[i,j] = cdp[int(tc_ind),j]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce3f11",
   "metadata": {},
   "source": [
    "### Plot the NMO corrected gather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c338f1d",
   "metadata": {},
   "source": [
    "## Exercise 2: (3/10): PCA\n",
    "Using PCA for denoising: \\\n",
    "Take the same CMP from the previous exercise and apply PCA compression, for example using a similar flow as in the lecture.\\\n",
    "A common way of plotting data is to clip based on a percentile (for example 98% of maximum). Can you figure how to do that using numpy?\\\n",
    "HINT: use np.percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c6f33",
   "metadata": {},
   "source": [
    "### Before NMO.\n",
    "Apply PCA thresholding to the whole gather."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc3099",
   "metadata": {},
   "source": [
    "### After NMO. \n",
    "Does it work better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d576393",
   "metadata": {},
   "source": [
    "### Random noise\n",
    "Add random noise to the gather. Does it remove efficiently?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752b744",
   "metadata": {},
   "source": [
    "### BONUS: +0.5/10 Small windows\n",
    "Divide the gather in small windows and do the same. Does it work better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8601895",
   "metadata": {},
   "source": [
    "## Exercise 3 (2/10): Linear Regression\n",
    "Use sklearn linear regression (perhaps with polynomial features) to interpolate the CDP gather below.\\\n",
    "For simplicity, use the original traces as the target (y). \\\n",
    "As an extension (not needed for the assignment) try to use the interpolator to the new cdp 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7637ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cdpgap=np.copy(cdp)\n",
    "cdpgap[:,20:25]=0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fbbc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(cdpgap,aspect='auto',clim=[-1000,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd79182",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt=726\n",
    "nx=48\n",
    "dt=0.004\n",
    "cdpnew = np.fromfile('cdp.3000b', dtype='float32')\n",
    "cdpnew=cdpnew.reshape((nx,nt))\n",
    "cdpnew=cdpnew.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6292d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdpnewgap=np.copy(cdpnew)\n",
    "cdpnewgap[:,20:25]=0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(cdpgap,aspect='auto',clim=[-1000,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11c8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('tfgpu3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b59a5e3ff7db1d615eca144819da7f336e272c88e568b42cc000e6824bfdb1ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
