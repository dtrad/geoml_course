{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "**Ian Allison, Compute Canada, 2020**\n",
    "(with changes for Geo-Machine Learning course)\n",
    "\n",
    "[Numpy](https://www.numpy.org/) is the foundation of most of what you will do with scientific python. \\\n",
    "Modules like [scipy](https://www.scipy.org/) and [pandas](https://pandas.pydata.org/) are built on top of numpy, and it is the linga franca for most numerical work in python. \\\n",
    "Numpy has a similar functionality as Matlab but with some design [differences](https://numpy.org/doc/stable/user/numpy-for-matlab-users.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/dtrad/geoml_course/blob/master/NumpyIntroSolved.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are first introduced to python, one of the big selling points is that it isn't statically typed. You can do things like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "a = 'apple'\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you don't get complaints from python about a being an integer. This is a _big_ advantage for python, and it works with collections as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3.0, 'Ian', [range(0, 3)], {'not': 'a good idea'}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myList = [1, 3., 'Ian', [range(3)], {'not': 'a good idea'}]\n",
    "myList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists in python are about as general as they could be. This is very flexible and it lets you do some fancy things in Python, but it has a price. The Python interpreter can't make any assumptions about what will come next in a list; everything has to be treated as a generic object. Python does a good job of hiding the complexity of doing this, but as the lists get longer and more complex the overhead gets larger, and eventually perfomance becomes unacceptable.\n",
    "\n",
    "One solution to this is to use a statically typed language like C[<sup>1</sup>](#fn1 \"footnote and tooltip 1\"). There the burden of figuring out object types is left to the programmer, and the compiler can be much more efficient operating on them. A good example would be an array of `double`s. In memory, these will be allocated contiguously so when you need to jump to the 1402th double, you can do it with very simple arithmetic. Python has a much harder time because the memory allocated for your list could be a horrible mixture of all the different things you've stuffed in there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `ndarray`\n",
    "\n",
    "Numpy attempts let you keep the advantages of Python without sacrifacing the speed of static typing by adding the concept of homogenous collections to python: `ndarray`s. The `ndarray` is the foundational concept in numpy, it is an array object which represents a multidimensional, homogeneous array of fixed-size items and Most commonly these items will be numbers.\n",
    "\n",
    "```\n",
    "%%timeit\n",
    "for i in range(1000000):\n",
    "    i*i\n",
    "```\n",
    "```\n",
    "%timeit np.arange(1000000)**2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 ms ± 2.66 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in range(1000000):\n",
    "    i*i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa=range(1000000)\n",
    "type(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "arange([start,] stop[, step,], dtype=None, *, like=None)\n",
      "\n",
      "Return evenly spaced values within a given interval.\n",
      "\n",
      "Values are generated within the half-open interval ``[start, stop)``\n",
      "(in other words, the interval including `start` but excluding `stop`).\n",
      "For integer arguments the function is equivalent to the Python built-in\n",
      "`range` function, but returns an ndarray rather than a list.\n",
      "\n",
      "When using a non-integer step, such as 0.1, it is often better to use\n",
      "`numpy.linspace`. See the warnings section below for more information.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "start : integer or real, optional\n",
      "    Start of interval.  The interval includes this value.  The default\n",
      "    start value is 0.\n",
      "stop : integer or real\n",
      "    End of interval.  The interval does not include this value, except\n",
      "    in some cases where `step` is not an integer and floating point\n",
      "    round-off affects the length of `out`.\n",
      "step : integer or real, optional\n",
      "    Spacing between values.  For any output `out`, this is the distance\n",
      "    between two adjacent values, ``out[i+1] - out[i]``.  The default\n",
      "    step size is 1.  If `step` is specified as a position argument,\n",
      "    `start` must also be given.\n",
      "dtype : dtype\n",
      "    The type of the output array.  If `dtype` is not given, infer the data\n",
      "    type from the other input arguments.\n",
      "like : array_like\n",
      "    Reference object to allow the creation of arrays which are not\n",
      "    NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "    the ``__array_function__`` protocol, the result will be defined\n",
      "    by it. In this case, it ensures the creation of an array object\n",
      "    compatible with that passed in via this argument.\n",
      "\n",
      "    .. versionadded:: 1.20.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "arange : ndarray\n",
      "    Array of evenly spaced values.\n",
      "\n",
      "    For floating point arguments, the length of the result is\n",
      "    ``ceil((stop - start)/step)``.  Because of floating point overflow,\n",
      "    this rule may result in the last element of `out` being greater\n",
      "    than `stop`.\n",
      "\n",
      "Warnings\n",
      "--------\n",
      "The length of the output might not be numerically stable.\n",
      "\n",
      "Another stability issue is due to the internal implementation of\n",
      "`numpy.arange`.\n",
      "The actual step value used to populate the array is\n",
      "``dtype(start + step) - dtype(start)`` and not `step`. Precision loss\n",
      "can occur here, due to casting or due to using floating points when\n",
      "`start` is much larger than `step`. This can lead to unexpected\n",
      "behaviour. For example::\n",
      "\n",
      "  >>> np.arange(0, 5, 0.5, dtype=int)\n",
      "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "  >>> np.arange(-3, 3, 0.5, dtype=int)\n",
      "  array([-3, -2, -1,  0,  1,  2,  3,  4,  5,  6,  7,  8])\n",
      "\n",
      "In such cases, the use of `numpy.linspace` should be preferred.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "numpy.linspace : Evenly spaced numbers with careful handling of endpoints.\n",
      "numpy.ogrid: Arrays of evenly spaced numbers in N-dimensions.\n",
      "numpy.mgrid: Grid-shaped arrays of evenly spaced numbers in N-dimensions.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> np.arange(3)\n",
      "array([0, 1, 2])\n",
      ">>> np.arange(3.0)\n",
      "array([ 0.,  1.,  2.])\n",
      ">>> np.arange(3,7)\n",
      "array([3, 4, 5, 6])\n",
      ">>> np.arange(3,7,2)\n",
      "array([3, 5])\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
     ]
    }
   ],
   "source": [
    "np.arange?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.61 ms ± 220 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.arange(1000000)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the line below to see the magic commands\n",
    "# %magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magic function system provides a series of functions which allow you to\n",
    "control the behavior of IPython itself, plus a lot of system-type\n",
    "features. There are two kinds of magics, line-oriented and cell-oriented.\n",
    "\n",
    "Line magics are prefixed with the % character and work much like OS\n",
    "command-line calls: they get as an argument the rest of the line, where\n",
    "arguments are passed without parentheses or quotes.  For example, this will\n",
    "time the given statement::\n",
    "\n",
    "        %timeit range(1000)\n",
    "\n",
    "Cell magics are prefixed with a double %%, and they are functions that get as\n",
    "an argument not only the rest of the line, but also the lines below it in a\n",
    "separate argument.  These magics are called with two arguments: the rest of the\n",
    "call line and the body of the cell, consisting of the lines below the first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ndarray`s look like python lists, but they are fundamentally different, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "b = [5, 6, 7, 8]\n",
    "print(a+b)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  8 10 12]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "na = np.array([1, 2, 3, 4])\n",
    "nb = np.array([5, 6, 7, 8])\n",
    "print(na + nb)\n",
    "print(type(na))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` was able to assume that the things in the `ndarray` were the compatible types and vectorize the addition, if we want the same thing with python lists, we have to jump through some hoops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 8, 10, 12]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ i + j for i, j in zip(a, b) ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what makes up an `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na = np.array([1,2,3,4,5])\n",
    "na.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<memory at 0x7f6573db4f40>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`a` has the following attributes,\n",
    "\n",
    "  * **ndim**: The number of dimensions\n",
    "  * **shape**: A tuple giving the sizes of the dimensions\n",
    "  * **size**: The total number of elements (product of the shape items)\n",
    "  * **dtype**: The data type, int64, float64, complex128 etc.\n",
    "  * **itemsize**: The size of individual elements in memory\n",
    "  * **nbytes**: The total memory occupied by the ndarray\n",
    "  * **strides**: Tuple of bytes to step in each dimension when traversing an array\n",
    "  * **data**: The buffer storing the contiguous identically typed items\n",
    "  \n",
    "By knowing these attributes, numpy can use some of the same tricks that statically typed languges use because the Python interpreter can now infer the memory layout.\n",
    "\n",
    "**Exercise**: Check the dtype of `a`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy has some convenience methods for creating new ndarrays. As you saw above, one way to create an ndarray is to pass a list with the values to `np.array`. Here are some others...\n",
    "\n",
    "Using np.array directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([0, 1, 1, 2, 3, 5, 8, 13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.arange` will generate numbers between limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = np.arange(0, 100,1)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a22 = np.arange(0, 10, dtype=float)\n",
    "a22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.linspace is extremely useful, you tell it where to start and stop and how many samples you need and linspace does the rest. Here we will create numbers 20 numbers between 0 (inclusive) and 1, linearly spaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.05263158, 0.10526316, 0.15789474, 0.21052632,\n",
       "       0.26315789, 0.31578947, 0.36842105, 0.42105263, 0.47368421,\n",
       "       0.52631579, 0.57894737, 0.63157895, 0.68421053, 0.73684211,\n",
       "       0.78947368, 0.84210526, 0.89473684, 0.94736842, 1.        ])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li1 = np.linspace(0, 1, 20)\n",
    "li1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.zeros` function will generate an `ndarray` full of zeros. The first argument is the shape which you can give as an integer (for 1d arrays) or a sequence (for n-dimensional arrays). You can also pass the `dtype=` argument to tell it what type of number you are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z1 100 integer zeros\n",
    "z1 = np.zeros(100, dtype=int)\n",
    "\n",
    "# z2 a 5,5 array of float64 zeros\n",
    "z2 = np.zeros((5, 5), dtype=np.float64)\n",
    "z2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.ones` function does something similar, but with unit value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o1 100 integers ones\n",
    "o1 = np.ones(100, dtype='float64')\n",
    "o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j],\n",
       "       [1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j],\n",
       "       [1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j],\n",
       "       [1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j],\n",
       "       [1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o2 a 5x5 ndarray of complex128 one values. First argument is shape sequence\n",
    "o2 = np.ones((5, 5), dtype='complex128')\n",
    "o2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.eye` function genrates a 2D array with ones down the diagonal, zeros elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e1 a 5x5 array with ones down the diagonal\n",
    "e1 = np.eye(5, dtype=np.float64)\n",
    "e1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll come back to the `numpy.random` module later on, but it has some useful convenience methods. `np.random.randint` returns random integers. Take a look at the help on the method then create a name `r1` with an array of `4x5` random numbers between `0` and `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 0, 5, 6, 2],\n",
       "       [0, 1, 9, 7, 9],\n",
       "       [0, 1, 2, 7, 9],\n",
       "       [5, 3, 7, 1, 8]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r1 a 4x5 array of random integers between 0 & 10, \n",
    "np.random.randint(0, 10, size=(4, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing\n",
    "\n",
    "Now that we have some `ndarray`s to play with, lets look at using them. Of course, `ndarray`s are zero indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First element of a2\n",
    "a2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual negative number notation works for couting from the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd to last element of a2\n",
    "a2[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can update `ndarray` in place by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2[-1] = 0\n",
    "a2[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing returns subarrays of the original `ndarray`. Crucially it does this inexpensively by returning a \"view\" on the data rather than copying it. This is much more efficient and relies on numpy is using it's knowledge of the memory layout to return only the things you ask for. This is a general tactic used by numpy, if it _can_ return a view rather than a copy it _will_! If you really need a copy, try the `.copy()` method on `ndarrays`.\n",
    "\n",
    "Slicing uses the same notation as core python: `[start:stop:step]` where `start` is inclusive and `stop` is exclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Values between 3 and 19 of a2\n",
    "a2[3:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  6,  9, 12, 15, 18])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every third value between 3 and 19\n",
    "a2[3:19:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using negative is allowed for all three parts of the slice, but for the step you have to think a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90, 91, 92, 93, 94, 95, 96, 97])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Values between -10 and -2\n",
    "a2[-10:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  9,  8,  7,  6,  5,  4,  3])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Values between 10 and 0, reversed\n",
    "a2[10:2:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first argument of the slice is still inclusive and the second is not. If we omit a value when specifying the slice `start` defaults to 0, `end` defaults to the last element and `step` defaults to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  6,  9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48,\n",
       "       51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96,  0])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2[::3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multi-dimensional arrays the indexing notation is similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(10, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "       [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       "       [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
       "       [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
       "       [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
       "       [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(100)\n",
    "print(b.shape)\n",
    "b.shape = (10, 10)\n",
    "print(b.shape)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about row 0, column 3 (remember python is 0 indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 39])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2:4,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 19, 29, 39, 49, 59, 69, 79, 89, 99])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the fifth column of the first two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 14])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0:2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  5],\n",
       "       [14, 15]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0:2, 4:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 29, 49, 69, 89])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[::2, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping Arrays\n",
    "\n",
    "Sometimes it is convenient to reshape arrays. I did this above by setting the `.shape` attribute but numpy arrays also have a reshape method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.arange(27)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reshape` expects a sequence as the first argument (we gave a tuple) so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
       "       [18, 19, 20, 21, 22, 23, 24, 25, 26]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = c.reshape((3, 9))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping isn't enough to provoke numpy to copy the data, all it needs to do is make a new view on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.base is c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.copy(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.base is c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common reshaping task is to add dimension(s) to an existing array. numpy has a special `newaxis` object for this task. This is a powerful idea when combined with numpy's broadcasting rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "e = np.arange(10)\n",
    "print(e.shape)\n",
    "ee=e[:, np.newaxis]\n",
    "print(ee.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "eee=e[np.newaxis, np.newaxis, :]\n",
    "print(eee.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory layout for multidimensional arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in memory can be in 'row' order or 'column' order (like C or like fortran). \n",
    "Default is row order (like c). This is very important in large multidimensional arrays like in seismic.\n",
    "see https://ncar-hackathons.github.io/scientific-computing/numpy/02_memory_layout.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arrc = np.array([[1, 2, 3], [11, 12, 13], [21, 22, 23]], \n",
    "                dtype='uint8', order='C')\n",
    "arrf = np.array([[1, 2, 3], [11, 12, 13], [21, 22, 23]], \n",
    "                dtype='uint8', order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1  2  3  11  12  13  21  22  23'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'  '.join(str(x) for x in np.nditer(arrc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1  11  21  2  12  22  3  13  23'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'  '.join(str(x) for x in np.nditer(arrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  C_CONTIGUOUS : True\n",
       "  F_CONTIGUOUS : False\n",
       "  OWNDATA : True\n",
       "  WRITEABLE : True\n",
       "  ALIGNED : True\n",
       "  WRITEBACKIFCOPY : False\n",
       "  UPDATEIFCOPY : False"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrc.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  C_CONTIGUOUS : False\n",
       "  F_CONTIGUOUS : True\n",
       "  OWNDATA : True\n",
       "  WRITEABLE : True\n",
       "  ALIGNED : True\n",
       "  WRITEBACKIFCOPY : False\n",
       "  UPDATEIFCOPY : False"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrf.flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking & Splitting ndarrays\n",
    "\n",
    "You can combine general ndarrays with the `np.concatenate` and split them with `np.split`. There are also a number of convenience methods for commonly used shapes.\n",
    "\n",
    " * `hstack`\n",
    " * `vstack`\n",
    " * `hsplit`\n",
    " * `vsplit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hstack` is short for horizontal stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,) (4,)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([4, 3, 2, 1])\n",
    "print(a.shape, b.shape)\n",
    "ab=np.hstack((a, b))\n",
    "print(ab.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `2D` arrays this means we are joining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n",
      "(4, 1)\n",
      "(4, 2)\n",
      "[[1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 4]]\n"
     ]
    }
   ],
   "source": [
    "aa=a[np.newaxis,:]\n",
    "bb=a[np.newaxis,:]\n",
    "print(aa.T.shape)\n",
    "print(bb.T.shape)\n",
    "\n",
    "cc=np.hstack((aa.T, bb.T))\n",
    "print(cc.shape)\n",
    "print(cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vstack does the equivalent thing but vertically stacking (along axis 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((a[:, np.newaxis], b[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In higher dimensions `concatenate` or `stack` should do what you need, but you need to manually tell it which axis to use for the stacking.\n",
    "\n",
    "`np.split` goes in the opposite direction. It will try to produce sub-arrays of equal size. Again there are `hsplit` and `vsplit` variants for common use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
       "        [16, 17, 18, 19, 20, 21, 22, 23],\n",
       "        [24, 25, 26, 27, 28, 29, 30, 31]]),\n",
       " array([[32, 33, 34, 35, 36, 37, 38, 39],\n",
       "        [40, 41, 42, 43, 44, 45, 46, 47],\n",
       "        [48, 49, 50, 51, 52, 53, 54, 55],\n",
       "        [56, 57, 58, 59, 60, 61, 62, 63]])]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.split(np.arange(64).reshape((8, 8)), 2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0,  1,  2,  3],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [16, 17, 18, 19],\n",
       "        [24, 25, 26, 27],\n",
       "        [32, 33, 34, 35],\n",
       "        [40, 41, 42, 43],\n",
       "        [48, 49, 50, 51],\n",
       "        [56, 57, 58, 59]]),\n",
       " array([[ 4,  5,  6,  7],\n",
       "        [12, 13, 14, 15],\n",
       "        [20, 21, 22, 23],\n",
       "        [28, 29, 30, 31],\n",
       "        [36, 37, 38, 39],\n",
       "        [44, 45, 46, 47],\n",
       "        [52, 53, 54, 55],\n",
       "        [60, 61, 62, 63]])]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.split(np.arange(64).reshape((8, 8)), 2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Functions (ufuncs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real reason for using numpy is so you can do numerical operations, _quickly_. Python uses a concept called `ufuncs` or universal function. A ufunc is a function which operates on `ndarrays` element-by-element. In other language a ufunc is a vectorized wrapper around a function which can do a transformation on an `ndarray` and produces another `ndarray`. This element by element behaviour is fundamentally different from the usual python behaviour.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "The key to writing fast numeric python code is: **Avoid for & while loops as far as you can, use numpy ufuncs as far as possible**\n",
    "\n",
    "\n",
    "Lets start with basic arithmetic operations. Numpy can use it's internal broadcasting to do these quickly and efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual operations are available\n",
    "\n",
    "  * +: addition\n",
    "  * -: subtraction\n",
    "  * *: multiplication\n",
    "  * /: division\n",
    "  * //: integer division\n",
    "  * **: power operator\n",
    "  * %: modulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations are element by element, and you can build up more complicated expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = np.linspace(0, 1, 100)\n",
    "\n",
    "(la ** 2 + la) / (la + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Try to calculate the terms of this sum as an `ndarray`\n",
    "$$\n",
    "\\sqrt{12}\\sum_{k=0}^{10}\\frac{(-3)^{-k}}{2k+1}\n",
    "$$\n",
    "\n",
    "_Hints_: Think term by term. `np.arange(10)` will give you an `ndarray` of k values, next raise `-3. * np.ones(k.shape)` to those powers. If you can calculate the terms you can use the `.sum()` method to sum them all up. How close to $\\pi$ did you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(10)\n",
    "\n",
    "np.sqrt(12) * ((-3 * np.ones(len(k)))**-k / (2 * k + 1)).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operators we were using `+,-,/,...` actually correspond to functions (`ufuncs`)\n",
    "\n",
    "|operator|function|description|\n",
    "|--------|--------|-----------|\n",
    "| + | np.add | Addition |\n",
    "| - | np.subtract | Subtraction |\n",
    "| - | np.negative | Unary negation |\n",
    "| * | np.multiply | Multiplication |\n",
    "| / | np.division | Ordinary floating point division |\n",
    "| // | np.floor_divide | floor (integer) division |\n",
    "| % | np.mod | Modulo/Remainder division |\n",
    "\n",
    "You can use either syntax, but in the function notation there are lots more functions to play with e.g.\n",
    "\n",
    "| function | description |\n",
    "|----------|-------------|\n",
    "| np.sin   | sin function |\n",
    "| np.cos   | cos function |\n",
    "| np.tan   | tan function |\n",
    "| np.abs   | absolute value |\n",
    "| np.exp   | exponential |\n",
    "| np.log   | natural log |\n",
    "| np.log2  | log base 2 |\n",
    "| np.log10 | log base 10 |\n",
    "|  ...     |    ...      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.linspace(0, 2*np.pi, 25)\n",
    "p2 = np.sin(p1)\n",
    "p2\n",
    "\n",
    "# p2 sin of p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.linspace(0, 1, 10) + np.linspace(1, 2, 10)*1j\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Functions\n",
    "\n",
    "In general, aggreate funcions calculate numbers that give insight into the nature of a potentially large dataset. They exists in all libraries (example we will use them a lot in Pandas). \\\n",
    "Aggregate functions take an `ndarray` and reduce it along one (or more) axes. An example would be taking an array of numbers and calculating the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.linspace(0, 10, 100)\n",
    "r1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are lots of aggregate functions\n",
    "\n",
    "  * `min`: Minimum value\n",
    "  * `max`: Maximum value\n",
    "  * `sum`: Sum values\n",
    "  * `prod`: Product of values\n",
    "  * `mean`: Arthmetic mean\n",
    "  * `std`: Standard deviation\n",
    "  * `var`: Variance\n",
    "  * `argmin`: indices of the minimum value\n",
    "  * `argmax`: indices of the maximum value\n",
    "  * `all`: is a condition true in all elements\n",
    "  * `any`: is a condition true in any elements\n",
    "  * `allclose`: All the values are within a small tolerance **really useful!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default is to reduce along all axes, if you want to reduce along a specific axis you can pass that as an argument (the axes you specify are the ones which get squashed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = np.arange(50)\n",
    "s2 = s1.reshape(5,10)\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For binary operations (e.g. addition) you can also do reduction, so starting from\n",
    "\n",
    "[1, 3, 5, 7, 9]\n",
    "\n",
    "`np.add.reduce` will add 1 to 3, add that to 5 and so on, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.arange(1, 10, 2)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add.reduce(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. In this case we used a function from the module and passed in our ndarray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing with Booleans and \"fancy\" indexing\n",
    "\n",
    "numpy has some more advanced tricks up it's sleeve when indexing. If we do a boolean test on an `ndarray` the result will be the same shape as the `ndarray` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = np.linspace(0, 1, 100)\n",
    "\n",
    "u1 < 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy will let us use this to index arrays of the same shape (see also `np.where`)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1[u1 < 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do other things with the boolean values like `.count_nonzero` them, checking if `.all` values or `.any` values are true etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(u1 < 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(u1 > 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(u1[u1 < 0.5] > 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy Indexing\n",
    "\n",
    "Fancy indexing is conceptually simple: it means passing an array of indices to access multiple array elements at once. \\\n",
    "Fancy is the idea of using an array of indices to access another array, it is useful when the combinations you want to select become a bit more complicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=np.arange(27)[::-1]\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1[[1, 4, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = v1.reshape(3,9)\n",
    "v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In higher dimensions think of zipping together the arguements, e.g. 0-th row, 4th column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2[[0, 1, 1], [3, 7, 8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*N.B. Fancy indexing usually creates copies of the `ndarray` because you usually can't reconstruct the selection with simple algebra*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters\n",
    "Adding a [] after the array, we can filter the output. This works in numpy and other structures (like panda dataframes). \\\n",
    "It is very common and may be confusing if you are trying to understand the [] part as a normal indexing since it looks like we are accessing one more index than the array has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pp=np.arange(10)\n",
    "ff=np.zeros(shape=pp.shape)\n",
    "ff[4:]=1\n",
    "ppp=pp[:]\n",
    "print(ppp)\n",
    "ppp=pp[:][ff>0]\n",
    "print(ppp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more confusing can be the following, which is very common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp=pp[:][pp>3]\n",
    "print(ppp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even use the same array, but be careful because on that case you can not run the same cell twice without redefining the original array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=pp[:][pp>3]\n",
    "print(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "`numpy` is at it's most efficient when it is operating element by element, but not all arrays are the same size. To work around this, `numpy` implements a set of rules under the name of `broadcasting` to make `ndarray`s conform whenever possible. This is great news, in that you don't have to worry about doing that yourself, but it is important to understand the rules so that you know how `numpy` will behave when combining different shaped `nbdarrays`. Conceptually, think of\n",
    "```python\n",
    "np.arange(10) * 5\n",
    "```\n",
    "`numpy` wants to operate element-by-element, but `5` isn't an `ndarray`, it's just a number. If we could promote 5 to be a `1d` narray and put 5's in in every place `numpy` would be happy. This is the basic idea of broadcasting, in summary\n",
    "\n",
    "1. Given two arrays of different dimensions, prepend 1, to the shape of the smaller array\n",
    "1. Dimensions of size 1 are repeated (without copying)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(15)\n",
    "a = a.reshape(3, 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.arange(5)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking through the rules manually, `b` has the smaller dimensions (1 vs. 2) so a dimension of length one will be prepended to `b`. `b` will then be repeated 3 times to conform with the shape of a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btmp = np.repeat(b[np.newaxis, :], 3, axis=0)\n",
    "btmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape, btmp.shape)\n",
    "a * btmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now again, but using the rules implicitly via broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape, b.shape)\n",
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Binary Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.arange(1,10)\n",
    "b=np.power(a,2)\n",
    "[(a[i],b[i]) for i in np.arange(len(a))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('array.npz',a=a,b=b)\n",
    "!ls  -lth *.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del a, b\n",
    "except:\n",
    "    pass\n",
    "ab=np.load('array.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ab['a']\n",
    "b=ab['b']\n",
    "[(a[i],b[i]) for i in np.arange(len(a))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Random\n",
    "\n",
    "Numpy has a few important submodules but `np.random` is probably the most important. As you might expect, it lets you work with random numbers but it goes far beyond simple a few random integers. You can make random samples from `ndarray`s, shuffle and permute sequences, draw samples from 30+ distributions and you can do it all quickly! Of course these are going to be pseudo-random numbers.\n",
    "\n",
    "`numpy.random` uses the concept of a `Generators` to implement sampling. The idea is you create a generator object then call methods on that generator to sample from the various distributions. The original `Generator` will normally get it's first value from a random or given seed; then you can keep asking it for the `__next__` random elements distributed however you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've seeded the `Generator` with a specific value so the results are reproducible but normally you would just call `np.random.default_rng()` to get a random value from the OS. Now we can sample from various distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.normal(5.0, 1.0, (64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.binomial(10, .5, size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 random integers between 10 and 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.integers(10, 20, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.random` also has functions for shuffling arrays in-place (`np.shuffle`) and selecting elements at random from `ndarrays` (`np.choice`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "np.random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "np.random.choice(a, 3, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also weight the selections in `np.choice` with probabilities. e.g. Here are the letter frequencies of ordinary english text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_freq = {' ': 0.19266420666588144,\n",
    " 'e': 0.09680968984305797,\n",
    " 't': 0.07140241019840815,\n",
    " 'a': 0.06361581392196947,\n",
    " 'o': 0.06183938572048604,\n",
    " 'i': 0.05349452953695084,\n",
    " 'n': 0.0521037201730283,\n",
    " 'h': 0.051232447485652234,\n",
    " 's': 0.049280151278754014,\n",
    " 'r': 0.04524648142979075,\n",
    " 'd': 0.03375374929612461,\n",
    " 'l': 0.03124157971419029,\n",
    " 'u': 0.02392934301198968,\n",
    " 'm': 0.021518821910249234,\n",
    " 'w': 0.020208685943305965,\n",
    " 'c': 0.02004895261728702,\n",
    " 'f': 0.016262143363080305,\n",
    " 'y': 0.016250849087503207,\n",
    " 'g': 0.013559584564274916,\n",
    " 'p': 0.012933559003715817,\n",
    " ',': 0.012259129404969158,\n",
    " '.': 0.01200420147051468,\n",
    " 'b': 0.011160357738111564,\n",
    " 'v': 0.0076220225466009876,\n",
    " 'k': 0.006392559976636984,\n",
    " 'x': 0.001353699601312072,\n",
    " 'j': 0.0008260955850676769,\n",
    " 'q': 0.0006663622590487316,\n",
    " 'z': 0.00031946665203789066\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use those relative frequency values as probabilities (they sum to ~1) and generate a random sample of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = np.array(list(letter_freq.keys()))\n",
    "probabilities = np.array(list(letter_freq.values()))\n",
    "chosen = np.random.choice(letters, 1000, p=probabilities)\n",
    "''.join(chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "fname = \"https://raw.githubusercontent.com/dtrad/geoml_course/master/crewes.jpg\"   \n",
    "#fname = \"crewes.jpg\"\n",
    "crewes = io.imread(fname)                      #Read the image from url as a numpy array\n",
    "#crewes = mpimg.imread(\"crewes.jpg\") # read the image from disk as a numpy ndarray\n",
    "plt.figure(figsize=(5,5));\n",
    "plt.imshow(crewes), plt.axis('off'), plt.show();\n",
    "print(type(crewes))\n",
    "print('image size = ',crewes.shape)\n",
    "print('value for one pixel', crewes[100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx, ly, _ = crewes.shape\n",
    "X, Y = np.ogrid[0:lx, 0:ly]\n",
    "mask = (X - lx / 2) ** 2 + (Y - ly / 2) ** 2 > lx * ly / 3\n",
    "crewes2=crewes.copy()\n",
    "crewes2[mask,:] = 0 # masks\n",
    "plt.figure(figsize=(5,5));\n",
    "plt.imshow(crewes2), plt.axis('off'), plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other stuff?\n",
    "  * `_ix()`\n",
    "  * a.copy()\n",
    "  * np.linalg\n",
    "  * np.matrixlib\n",
    "  * np.fft\n",
    "  * Applications? Simple monte-carlo? Images?\n",
    "  * np.set_printoptions?\n",
    "  * memory layouts and strides?\n",
    "  * .flatten (copy) and ravel (view if possible)\n",
    "  * mgrid & ogrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Footnotes\n",
    "[1]<span id=\"fn1\"> If you dig deep enough in some of the numpy/scipy code you will find that the actual instructions you are executing were compiled from fortran and C. In general you can pass things quite easily between existing libraries and python, but fortran and C use different storage orders for multi-dimensional arrays so you have to be a little bit careful_.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('tfgpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bcb505fb65f009327e3568b030955b94ed789ec146fa5e9e6be7faa0a986839b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
